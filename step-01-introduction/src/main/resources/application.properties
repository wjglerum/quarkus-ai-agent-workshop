# Enable OpenAI with your OPENAI_API_KEY
#quarkus.langchain4j.chat-model.provider=openai
#quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
#quarkus.langchain4j.openai.chat-model.model-name=gpt-4o

# Enable Ollama with OpenAI compatibility
#quarkus.langchain4j.chat-model.provider=openai
#quarkus.langchain4j.openai.base-url=http://localhost:11434/v1/
#quarkus.langchain4j.openai.chat-model.model-name=llama3.2

# Enable Google Gemini with your GEMINI_API_KEY
#quarkus.langchain4j.chat-model.provider=gemini
#quarkus.langchain4j.ai.gemini.api-key=${GEMINI_API_KEY}
#quarkus.langchain4j.ai.gemini.chat-model.model-id=gemini-2.5-flash

# Enable Ollama
quarkus.langchain4j.chat-model.provider=ollama
quarkus.langchain4j.ollama.chat-model.model-id=llama3.2

# Capture requests and response from the language model
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true

# Set larger timeout for local language models
quarkus.langchain4j.timeout=1m
